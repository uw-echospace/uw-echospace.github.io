<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>echolocation | Echospace @ UW</title><link>https://uw-echospace.github.io/tag/echolocation/</link><atom:link href="https://uw-echospace.github.io/tag/echolocation/index.xml" rel="self" type="application/rss+xml"/><description>echolocation</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 01 Jul 2022 00:00:00 +0000</lastBuildDate><image><url>https://uw-echospace.github.io/images/icon_hu9a3e81eca2a83564e549c2cdc32b0637_27049_512x512_fill_lanczos_center_2.png</url><title>echolocation</title><link>https://uw-echospace.github.io/tag/echolocation/</link></image><item><title>Passive acoustic monitoring of bats in the Union Bay Natural Area</title><link>https://uw-echospace.github.io/project/ubna-pam/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/project/ubna-pam/</guid><description>&lt;p>Understanding how echolocators make use of sound to navigate their surroundings has great potential for informing the design of advanced acoustic sensing technologies. Although much has already been studied in laboratory experiments, technology has just started catching up to allow researchers to study echolocation-related processes in the wild. Advancements in passive acoustic monitoring tools have made it affordable to conduct long-term acoustic surveys on animals in the wild. Echolocators, like bats, are well-suited for monitoring using simple passive acoustic techniques because of their use of acoustics and navgitaion in air.&lt;/p>
&lt;p>In this project, we sought to collect long-term acoustic data using Audiomoths from an urban natural area called the Union Bay Natural Area at the University of Washington. With this data, we hope to uncover questions on how environmental conditions influence how bats choose to forage.&lt;/p>
&lt;p>&lt;strong>Funding&lt;/strong>:
&lt;a href="https://www.washington.edu/research/or/royalty-research-fund-rrf/" target="_blank" rel="noopener">UW Royalty Research Fund&lt;/a>&lt;/p></description></item><item><title>Modeling sound propagation in the head of toothed whales</title><link>https://uw-echospace.github.io/project/echolocation-comsol/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/project/echolocation-comsol/</guid><description>&lt;p>Toothed whales, including species such as porpoises, dolphins, orca, and sperm whale, possess highly specialized anatomical structures in the head to support their biosonar systems - echolocation - through millions of years of evoluation. These animals have the remarkable ability to detect and track small targets over long distance and discriminate between minute differences between targets using echolocation, with performance often surpassing that of current human-made sonar systems. However, many questions remain in how exactly the unusual anatomical structures in the head of toothed whales are orchestrated to support such performance.&lt;/p>
&lt;p>As part of a Multidisciplinary University Research Initiative (MURI) project, we use finite element modeling techniques in combination with volumetric representations derived from computed tomography (CT) scans to predict the head-related transfer functions (HRTFs) of a dolphin head. The HRTFs summarizes the influence of the head to sounds propagating to the ears. We use HRTFs as a biologically meaningful proxy to provide a physics-based mechanistic understanding of the sound transduction processes.&lt;/p>
&lt;!-- TODO: link ASA 2023 talk -->
&lt;p>&lt;strong>Funding&lt;/strong>: Office of Naval Research, Multidisciplinary University Research Initiative (MURI) program&lt;/p></description></item><item><title>Target search and discrimination by echolocating toothed whales</title><link>https://uw-echospace.github.io/project/echolocation-search/</link><pubDate>Thu, 01 Jan 1970 00:33:38 +0000</pubDate><guid>https://uw-echospace.github.io/project/echolocation-search/</guid><description>&lt;p>Echolocating animals effortlessly navigate, hunt, and interact with their environment, despite cluttered and noisy return signals. Blind expert human echolocators prove that this capacity does not depend exclusively on biological specializations unique to particular species. This project is an integrated component of a larger collaborative Multidisciplinary University Research Initiative (MURI) project focused on active sensing in echolocating marine mammals and humans. The MURI team use both toothed whales (odontocetes) and humans as model systems to identify the neural mechanisms that extract echo-acoustic information and the brain networks that build and learn robust, invariant representations of auditory objects in complex auditory scenes.&lt;/p>
&lt;p>In Echospace, we undertake two interconnected components of this project:&lt;/p>
&lt;ul>
&lt;li>Model the echolocation-based target search by toothed whales as an information-seeking behavior by extending the &lt;em>infotaxis&lt;/em> algorithm originally formulated in moth odor tracking problems into an &lt;em>active sensing&lt;/em> context&lt;/li>
&lt;/ul>
&lt;!-- TODO: link ASA 2019 talk -->
&lt;ul>
&lt;li>Conduct and analyze the coupled acoustic sampling and movement behaviors of an echolocating harbor porpoise in a target discrimination experiment&lt;/li>
&lt;/ul>
&lt;!-- TODO: link ASA 2021, 2023 talks -->
&lt;p>&lt;strong>Funding agency&lt;/strong>: Office of Naval Research, Multidisciplinary University Research Initiative (MURI) program&lt;/p></description></item><item><title>Understanding echoes</title><link>https://uw-echospace.github.io/talk/202205-asa-denver-keynote/</link><pubDate>Mon, 23 May 2022 16:10:00 +0200</pubDate><guid>https://uw-echospace.github.io/talk/202205-asa-denver-keynote/</guid><description/></item></channel></rss>