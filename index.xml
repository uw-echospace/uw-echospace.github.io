<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Echospace @ UW</title><link>https://uw-echospace.github.io/</link><atom:link href="https://uw-echospace.github.io/index.xml" rel="self" type="application/rss+xml"/><description>Echospace @ UW</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 09 Oct 2024 00:00:00 +0000</lastBuildDate><image><url>https://uw-echospace.github.io/images/icon_hu9a3e81eca2a83564e549c2cdc32b0637_27049_512x512_fill_lanczos_center_2.png</url><title>Echospace @ UW</title><link>https://uw-echospace.github.io/</link></image><item><title>Code of Conduct &amp; What we value</title><link>https://uw-echospace.github.io/group/coc/</link><pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/group/coc/</guid><description>&lt;h3 id="why">Why&lt;/h3>
&lt;ul>
&lt;li>We respect and want to take advantage of the diversity of background and expertise in the group.&lt;/li>
&lt;li>We also want to create an optimal learning and research environment for everyone.&lt;/li>
&lt;/ul>
&lt;h3 id="code-of-conduct">Code of Conduct&lt;/h3>
&lt;p>Echospace is dedicated to providing a harassment-free experience for everyone, regardless of gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, or religion (or lack thereof). We do not tolerate harassment of group members in any form. Sexual language and imagery is not appropriate for any group venue, including meetings, presentations, or discussions, and in both physical and online spaces.&lt;/p>
&lt;h3 id="what-we-value">What we value&lt;/h3>
&lt;ul>
&lt;li>Be proactive
&lt;ul>
&lt;li>Say hello to people you meet at work (in the morning when you come to work, etc)&lt;/li>
&lt;li>Be on time and respect other’s time, communicate if you don’t have time&lt;/li>
&lt;li>Don’t be afraid of being wrong and ask, and answer to questions from others kindly&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Be open to change&lt;/li>
&lt;li>Communication
&lt;ul>
&lt;li>Respect other person’s background may be different from yours&lt;/li>
&lt;li>Be welcoming to others’ perspectives and what makes them tick, what excites them&lt;/li>
&lt;li>Don’t assume people know or don’t know what you’re talking about, it is ok and often better to just ask&lt;/li>
&lt;li>When there are different opinions, try to convince others by reasoning, and avoid being dismissive because of others’ career stages or rank&lt;/li>
&lt;li>Strive to communicate, both when we don’t think we understand what the other person is saying and when we think we are not being understood (misunderstandings)&lt;/li>
&lt;li>Acknowledge contributions from others&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Ask questions and provide feedback kindly
&lt;ul>
&lt;li>Use “we” instead of “you”&lt;/li>
&lt;li>Use sandwich method: start with positive statement, follow with the comment “have you consider XYZ”, and end with positive affirmation/offer support&lt;/li>
&lt;li>Provide constructive feedback, elaborate on your comments, and be willing to explain more&lt;/li>
&lt;li>Value listening to others, and asking respectful questions&lt;/li>
&lt;li>&lt;strong>Provide positive feedback too!&lt;/strong>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Group interaction and collaboration
&lt;ul>
&lt;li>Have clear expectations and communicate openly, to avoid last minute surprises&lt;/li>
&lt;li>Ensure everyone has the opportunity to participate both online and in person&lt;/li>
&lt;li>Give opportunities to others to speak first&lt;/li>
&lt;li>Make accommodations for personal emergencies&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Help each other grow
&lt;ul>
&lt;li>Provide opportunities for peer mentoring&lt;/li>
&lt;li>Sharing opportunities in the group that others might be interested in (or would want to be involved in)&lt;/li>
&lt;li>Enable and encourage growth by everyone in the group, in directions that align with what they’re interested in&lt;/li>
&lt;li>Be comfortable bringing up issues or obstacles that hold you back from getting work done&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="feedback-sharing">Feedback Sharing&lt;/h2>
&lt;p>Provide feedback on what to improve either in person or use the
&lt;a href="https://forms.gle/NZFZBQLk9BoMLZCV6" target="_blank" rel="noopener">Echospace Anonymous Feedback Form&lt;/a> if you prefer to remain anonymous. The form requires one to be logged with their &lt;code>uw&lt;/code> email address, but we will not have access to it.&lt;/p>
&lt;h2 id="conflict-resolution">Conflict Resolution&lt;/h2>
&lt;p>If you see something inappropriate, let Wu-Jung or Valentina know immediately, or contact the
&lt;a href="https://www.washington.edu/ombud/" target="_blank" rel="noopener">Office of the Ombud&lt;/a> for support in conflict resolution. You can refer to some additional resources from the UW HR office
&lt;a href="https://hr.uw.edu/policies/complaint-resolution/" target="_blank" rel="noopener">here&lt;/a> or refer to your department for advice.&lt;/p></description></item><item><title>BOAT: Bridge to Ocean Acoustics and Technology</title><link>https://uw-echospace.github.io/project/boat/</link><pubDate>Thu, 28 Mar 2024 17:02:36 -0800</pubDate><guid>https://uw-echospace.github.io/project/boat/</guid><description>&lt;p>
&lt;a href="https://uw-echospace.github.io/author/wu-jung-lee">Wu-Jung Lee&lt;/a> (APL),
&lt;a href="https://uw-echospace.github.io/author/valentina-staneva">Valentina Staneva&lt;/a> (eScience Institute), and
&lt;a href="https://www.apl.washington.edu/people/profile.php?last_name=Hefner&amp;amp;first_name=Todd" target="_blank" rel="noopener">Todd Hefner&lt;/a> (APL) were awarded a grant by the Office of Naval Research to democratize ocean acoustics education and research training. The new program BOAT: Bridge to Ocean Acoustics and Technology will develop open source education curriculum&amp;amp;tutorials and interactive training workshops that aim to prepare students from diverse backgrounds (biology, physics, electrical engineering, math, etc) for doing research in the interdisciplinary field of Ocean Acoustics. The modules will cover topics ranging from the scientific theory (physics) of scattering of the seabed and marine organisms, practical applications in oceanography and fisheries, to foundational topics in statistics, machine learning, and data science workflows which all are indispensable in navigating today’s data-rich science. They will be provided in the form of
&lt;a href="https://ebooks.iospress.nl/publication/42900" target="_blank" rel="noopener">Jupyter Notebooks&lt;/a> with interactive components, which can be adapted and ingested in various settings such as a university course or a summer workshop, and will serve as blueprints for building resources on other ocean acoustics topics. The goal is to build a community of practitioners who build and share knowledge on best practices on how to teach and train new scientists in the field. For those interested in learning more about the program and/or exploring potential collaborations, please, reach out to the PIs at emails: &lt;code>leewj@uw.edu&lt;/code>, &lt;code>vms16@uw.edu&lt;/code>, &lt;code>bth3@uw.edu&lt;/code>.&lt;/p>
&lt;p>&lt;strong>Funding Agency:&lt;/strong> Office of Naval Research&lt;/p></description></item><item><title>Analyzing the effects of environmental conditions on bat activity</title><link>https://uw-echospace.github.io/project_others/2024-ubna-weather/</link><pubDate>Fri, 15 Mar 2024 17:02:36 -0800</pubDate><guid>https://uw-echospace.github.io/project_others/2024-ubna-weather/</guid><description>&lt;p>As global warming accelerates and continues to reshape regional climates, changes in local weather patterns, such as rising temperatures, irregular rainfalls, and random forest fires, can profoundly alter bat behavior, foraging patterns, and migration timing, affecting the overall health of the entire bat communities. Therefore, understanding which environmental conditions have an impact on bat activity, and to what extent, is critical to developing effective conservation strategies in one region.&lt;/p>
&lt;p>With the Union Bay Natural Area at the University of Washington as a research site, using bat echolocation call detections from the
&lt;a href="https://uw-echospace.github.io/project/2022-ubna-pam/" target="_blank" rel="noopener">UBNA passive acoustic monitoring program&lt;/a>, meteorological data from the University of Washington weather station, and lunar phase data from NASA, the project aims to find the environmental factors that influence bat activity and explore the effects of extreme stormy weather on local bat emergence through statistical testing and inference.&lt;/p>
&lt;p>Funding:
&lt;a href="https://www.washington.edu/research/or/royalty-research-fund-rrf/" target="_blank" rel="noopener">UW Royalty Research Fund&lt;/a>&lt;/p></description></item><item><title>UBNA passive acoustic monitoring project</title><link>https://uw-echospace.github.io/project_others/2022-ubna-pam/</link><pubDate>Wed, 01 Sep 2021 17:02:36 -0800</pubDate><guid>https://uw-echospace.github.io/project_others/2022-ubna-pam/</guid><description>&lt;p>Understanding how echolocators make use of sound to navigate their surroundings has great potential for informing the design of advanced acoustic sensing technologies. Although much has already been studied in laboratory experiments, technology has just started catching up to allow researchers to study echolocation-related processes in the wild. Advancements in passive acoustic monitoring tools have made it affordable to conduct long-term acoustic surveys on animals in the wild. Echolocators, like bats, are well-suited for monitoring using simple passive acoustic techniques because of their use of acoustics and navgitaion in air.&lt;/p>
&lt;p>In this project, we sought to collect long-term acoustic data using Audiomoths from an urban natural area called the Union Bay Natural Area at the University of Washington. With this data, we hope to uncover questions on how environmental conditions influence how bats choose to forage.&lt;/p>
&lt;p>&lt;strong>Funding agency&lt;/strong>:
&lt;a href="https://www.washington.edu/research/or/royalty-research-fund-rrf/" target="_blank" rel="noopener">University of Washington Royalty Research Fund&lt;/a>&lt;/p></description></item><item><title>Passive acoustic monitoring of bats in the Union Bay Natural Area</title><link>https://uw-echospace.github.io/project/ubna-pam/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/project/ubna-pam/</guid><description>&lt;p>Understanding how echolocators make use of sound to navigate their surroundings has great potential for informing the design of advanced acoustic sensing technologies. Although much has already been studied in laboratory experiments, technology has just started catching up to allow researchers to study echolocation-related processes in the wild. Advancements in passive acoustic monitoring tools have made it affordable to conduct long-term acoustic surveys on animals in the wild. Echolocators, like bats, are well-suited for monitoring using simple passive acoustic techniques because of their use of acoustics and navgitaion in air.&lt;/p>
&lt;p>In this project, we sought to collect long-term acoustic data using Audiomoths from an urban natural area called the Union Bay Natural Area at the University of Washington. With this data, we hope to uncover questions on how environmental conditions influence how bats choose to forage.&lt;/p>
&lt;p>&lt;strong>Funding&lt;/strong>:
&lt;a href="https://www.washington.edu/research/or/royalty-research-fund-rrf/" target="_blank" rel="noopener">UW Royalty Research Fund&lt;/a>&lt;/p></description></item><item><title>Machine learning in fisheries acoustics</title><link>https://uw-echospace.github.io/project/2021-hake-workflow/</link><pubDate>Sat, 01 May 2021 17:02:36 -0800</pubDate><guid>https://uw-echospace.github.io/project/2021-hake-workflow/</guid><description>&lt;p>Active acoustic data collected with scientific echosounders from acoustic surveys have become essential for stock assessment in fisheries resources management. Over the past three decades, a wide suite of physics-based acoustic scattering models were developed to allow translating acoustic observations to biological quantities, such as biomass and abundance, for different marine organisms. In parallel, quantitative scientific echosounders have progressed from specialized equipment to one of the standard instruments on fisheries survey vessels.&lt;/p>
&lt;p>To take full advantage of these large and complex new datasets, in this project we aim to combine the development of machine learning methodology with a cloud-based workflow to accelerate the extraction of biological information from fisheries acoustic data. Our group has developed and used
&lt;a href="https://echopype.readthedocs.io/en/stable/" target="_blank" rel="noopener">Echopype&lt;/a>, a Raw Sonar Backscatter data parsing Python package, and
&lt;a href="https://echoregions.readthedocs.io/en/latest/" target="_blank" rel="noopener">Echoregions&lt;/a>, an Echoview annotation data parsing Python package. Transferring data from Echoview and proprietary echosounder formats to Python data products enables seamless integration with a rich ecosystem of scientific computing tools developed by a vast community of open-source contributors, thus allowing us to use our data to train deep learning models to predict regions of interest in echograms.&lt;/p>
&lt;img src="featured.png" alt="Fisheries Acoustics">
&lt;p>This project is in close collaboration with the
&lt;a href="https://www.fisheries.noaa.gov/west-coast/sustainable-fisheries/fisheries-engineering-and-acoustic-technologies-team" target="_blank" rel="noopener">Fisheries Engineering and Acoustics Technology (FEAT) team&lt;/a> at the NOAA Fisheries
&lt;a href="https://www.fisheries.noaa.gov/about/northwest-fisheries-science-center" target="_blank" rel="noopener">Northwest Fisheries science center (NWFSC)&lt;/a> and uses data collected in the past 20 years off the west coast of the U.S. from the
&lt;a href="https://www.fisheries.noaa.gov/west-coast/science-data/joint-us-canada-integrated-ecosystem-and-pacific-hake-acoustic-trawl-survey" target="_blank" rel="noopener">Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic-Trawl Survey&lt;/a> (aka the &amp;ldquo;Hake survey&amp;rdquo;).&lt;/p>
&lt;p>&lt;strong>Funding agency&lt;/strong>: NOAA Fisheries&lt;/p></description></item><item><title>Scalable, cloud-native processing of water column sonar data</title><link>https://uw-echospace.github.io/project_others/2021-cloud-workflows/</link><pubDate>Sun, 24 Oct 2021 16:56:36 -0800</pubDate><guid>https://uw-echospace.github.io/project_others/2021-cloud-workflows/</guid><description>&lt;p>Scientists commonly use active sonar systems to collect data about mid-trophic level animals like zooplankton and small fish, which play an important role in the marine ecosystems. Echosounders, or fish-finders, are high-frequency sonar systems that emit pulses of sound and record the reflections from animals, the seabed, and other objects. These instruments have been proven to be more efficient and effective for collecting data over a large survey area or a long time period than many other sampling methods, such as underwater imaging and net trawls. This technology has been widely adopted by the ocean science and commercial fishing communities and more recently has been integrated with autonomous vehicles, resulting in a massive amount of data. However, these datasets can be difficult to analyze and are often underutilized. We will address this issue by adopting and advancing data standards, developing a streamlined data processing workflow, and integrating open-source software tools that capitalize on recent advancements in cloud computing technologies to efficiently transform large quantities of ocean sonar data into information that is useful for exploring, monitoring, and managing living marine resources.&lt;/p>
&lt;p>&lt;strong>Funding agency&lt;/strong>: NOAA Office of Ocean Exploration and Research
&lt;a href="https://oceanexplorer.noaa.gov/news/oer-updates/2021/fy21-ffo-schedule.html" target="_blank" rel="noopener">FY2021 grants&lt;/a>&lt;/p></description></item><item><title>The open-source "Echostack" for scalable, cloud-native processing of water column sonar data</title><link>https://uw-echospace.github.io/project/echostack/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/project/echostack/</guid><description>&lt;p>Water column sonar data collected by echosounders are essential for fisheries and marine ecosystem research, enabling the detection, classification, and quantification of fish and zooplankton from many different ocean observing platforms. However, the broad usage of these data has been hindered by the lack of modular software tools that allow flexible composition of data processing workflows that incorporate powerful analytical tools in the scientific Python ecosystem. We address this gap by developing &lt;strong>Echostack&lt;/strong>, a suite of open-source Python software packages that leverage existing distributed computing and cloud-interfacing libraries to support intuitive and scalable data access, processing, and interpretation. These tools can be used individually or orchestrated together, which we demonstrate in example use cases for a fisheries acoustic-trawl survey.&lt;/p>
&lt;p>Currently, the Echostack contains the following packages:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://github.com/OSOceanAcoustics/echopype" target="_blank" rel="noopener">Echopype&lt;/a>: performs data standardization and computation from raw instrument files to acoustic data products
&lt;ul>
&lt;li>Check out the
&lt;a href="https://doi.org/10.1093/icesjms/fsae133" target="_blank" rel="noopener">Echopype paper in ICES Journal of Marine Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;a href="https://github.com/OSOceanAcoustics/echopop" target="_blank" rel="noopener">Echopop&lt;/a>: generates acoustically derived biological estimates, such as abundance
&lt;ul>
&lt;li>Learn more on
&lt;a href="../../project_others/echopop/">Echopop project page&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;a href="https://github.com/OSOceanAcoustics/echoshader" target="_blank" rel="noopener">Echoshader&lt;/a>: enables interactive acoustic data visualization and exploration&lt;/li>
&lt;li>
&lt;a href="https://github.com/OSOceanAcoustics/echoregions" target="_blank" rel="noopener">Echoregions&lt;/a>: interfaces acoustic data with machine learning developments&lt;/li>
&lt;li>
&lt;a href="https://github.com/OSOceanAcoustics/echodataflow" target="_blank" rel="noopener">Echodataflow&lt;/a>: workflow orchestration via text-based configuration “recipes” instead of code&lt;/li>
&lt;/ul>
&lt;p>These packages are accompanied by a set of data processing level definitions,
&lt;a href="https://github.com/OSOceanAcoustics/echolevels" target="_blank" rel="noopener">Echolevels&lt;/a>, which categorizes data products at different workflow stages to enhance data understanding and provenance tracking.&lt;/p>
&lt;p>Check out Wu-Jung&amp;rsquo;s talk at SciPy 2024 and the associated
&lt;a href="https://doi.org/10.25080/WXRH8633" target="_blank" rel="noopener">proceeding paper&lt;/a>!
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/YRFxMGisGww" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/p>
&lt;p>&lt;strong>Funding&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>NOAA Fisheries&lt;/li>
&lt;li>NOAA Office of Ocean Exploration and Research
&lt;a href="https://oceanexplorer.noaa.gov/news/oer-updates/2021/fy21-ffo-schedule.html" target="_blank" rel="noopener">FY2021 grants&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Echopop: biomass estimation for Pacific Hake</title><link>https://uw-echospace.github.io/project_others/echopop/</link><pubDate>Tue, 25 Jan 2022 17:02:36 -0800</pubDate><guid>https://uw-echospace.github.io/project_others/echopop/</guid><description>&lt;p>Echopop is a software used for processing backscatter measurements and biological data collected from acoustic-trawl surveys to estimate population estimates and other metrics. The development of this software has been primarily focused on surveys targeting Pacific hake (&lt;strong>see below information for more details&lt;/strong>), but the goal is to generalize the software in the future for broader fisheries community use.&lt;/p>
&lt;p>The
&lt;a href="https://www.fisheries.noaa.gov/west-coast/sustainable-fisheries/fisheries-engineering-and-acoustic-technologies-team" target="_blank" rel="noopener">Fisheries Engineering and Acoustics Technology (FEAT) team&lt;/a> at the NOAA Fisheries
&lt;a href="https://www.fisheries.noaa.gov/about/northwest-fisheries-science-center" target="_blank" rel="noopener">Northwest Fisheries Science Center (NWFSC)&lt;/a> collaborates with
&lt;a href="https://www.dfo-mpo.gc.ca/index-eng.htm" target="_blank" rel="noopener">Fisheries and Oceans Canada (DFO) - Pacific Region&lt;/a> to estimate total biomass of
&lt;a href="https://www.fisheries.noaa.gov/species/pacific-whiting" target="_blank" rel="noopener">Pacific hake (&lt;i>Merluccius productus&lt;/i>)&lt;/a> by incorporating acoustic and biological trawl data from the
&lt;a href="https://www.fisheries.noaa.gov/west-coast/science-data/joint-us-canada-integrated-ecosystem-and-pacific-hake-acoustic-trawl-survey" target="_blank" rel="noopener">Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic-Trawl Survey&lt;/a> (aka the &amp;ldquo;Hake survey&amp;rdquo;).&lt;/p>
&lt;p>These biomass estimates are the inputs for the stock assessment of hake and need to be completed in an efficient and timely manner after the survey. The biomass estimates are currently produced by a suite of Matlab scripts operated by a single user, and the analysis procedures are not easily adaptable by other FEAT/DFO team members. The central objective of this project is to provide a well-documented open-source
&lt;a href="https://github.com/OSOceanAcoustics/echopop" target="_blank" rel="noopener">Python software package&lt;/a> (&lt;code>echopop&lt;/code>) that contains the core computational functionality of the current Matlab EchoPro program and provides basic visualization of the analysis results.&lt;/p>
&lt;p>The new software package (currently
&lt;a href="https://github.com/OSOceanAcoustics/echopop/releases/latest" target="_blank" rel="noopener">version 0.4.0&lt;/a> and available on
&lt;a href="https://pypi.org/project/echopop/" target="_blank" rel="noopener">PyPi&lt;/a>) contains an expanded
&lt;a href="https://echopop.readthedocs.io/en/latest/" target="_blank" rel="noopener">documentation&lt;/a> that details the underlying theory and algorithmic implementation that help facilitate reproducibility. Other features include an
&lt;a href="https://echopop.readthedocs.io/en/latest/api.html" target="_blank" rel="noopener">Application Programming Interface (API)&lt;/a> that can be invoked in a reproducible manner, a flexible analysis configuration that allows for both machine and human-readable parameterizations, and interactive Jupyter notebooks that exemplify various workflows
&lt;a href="https://echopop.readthedocs.io/en/latest/example_notebooks/example_echopop_workflow.html" target="_blank" rel="noopener">ranging from initial data processing to kriging&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Funding agency&lt;/strong>: NOAA Fisheries, NOAA NWFSC&lt;/p></description></item><item><title>Opportunities at Echospace</title><link>https://uw-echospace.github.io/group/opportunities/</link><pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/group/opportunities/</guid><description>&lt;h2 id="general-information">General information&lt;/h2>
&lt;p>We welcome researchers and students with diverse backgrounds to come work with us in Echospace! If you don&amp;rsquo;t see a specific position below, feel free to reach out to us directly. Please include a cover letter and a CV/resume when initiating the contact, so that we have a better idea what you are looking for and your background.&lt;/p>
&lt;h2 id="fellowship-opportunities">Fellowship opportunities&lt;/h2>
&lt;p>Below is a list of fellowship opportunities within and outside of UW. Relevant areas include but are not limited to fisheries and ocean acoustics, animal echolocation (bats and dolphins), marine ecology, and environmental data science. Feel free to reach out to us for questions and discussion.&lt;/p>
&lt;h3 id="postdoc-fellowships">Postdoc fellowships&lt;/h3>
&lt;h4 id="university-of-washington">University of Washington&lt;/h4>
&lt;ul>
&lt;li>
&lt;a href="https://ap.washington.edu/ahr/position-details/?job_id=99111" target="_blank" rel="noopener">APL SEED Postdoctoral Scholar Program&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://cicoes.uw.edu/education/postdoc-program/" target="_blank" rel="noopener">Cooperative Institute for Climate, Ocean, and Ecosystem Studies (CICOES) postdoctoral fellowship&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.wrfseattle.org/grants/wrf-postdoctoral-fellowships/" target="_blank" rel="noopener">Washington Research Foundation (WRF) Postdoctoral Fellowship&lt;/a>&lt;/li>
&lt;/ul>
&lt;h4 id="external">External&lt;/h4>
&lt;ul>
&lt;li>
&lt;a href="https://beta.nsf.gov/funding/opportunities/ocean-sciences-postdoctoral-research-fellowships-oce-prf-0" target="_blank" rel="noopener">NSF Ocean Sciences (OCE) Postdoctoral Research Fellowships (OCE-PRF)&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://beta.nsf.gov/funding/opportunities/ear-postdoctoral-fellowships-ear-pf" target="_blank" rel="noopener">NSF Division of Earth Sciences (EAR) Postdoctoral Fellowships (EAR-PF)&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://acousticalsociety.org/fellowships-and-scholarships/" target="_blank" rel="noopener">Acoustical Society of America (ASA) F. V. Hunt Postdoctoral Research fellowship&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="graduate-fellowships">Graduate fellowships&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="https://www.nsfgrfp.org/" target="_blank" rel="noopener">NSF Graduate Research Fellowships Program (GRFP)&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="undergraduate-fellowships">Undergraduate fellowships&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="https://expd.uw.edu/mge/apply/research/" target="_blank" rel="noopener">UW Mary Gates Research Scholarship&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.apl.uw.edu/education/dino_sip.php" target="_blank" rel="noopener">APL DINO-SIP Diverse + Inclusive Naval Oceanographic Summer Intership Program&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>ADCP-equipped underwater glider as a distributed biological sensing tool</title><link>https://uw-echospace.github.io/project/2020-glider-adcp/</link><pubDate>Tue, 01 Sep 2020 17:02:36 -0800</pubDate><guid>https://uw-echospace.github.io/project/2020-glider-adcp/</guid><description>&lt;p>Mid-trophic level animals, such as zooplankton and fish, are keystone organisms in the marine ecosystem and play a critical role in the economy and our food supply chain. However, our understanding of these animals, particularly those in the pelagic zones, is severely limited, due to the lack of tools that cab . This gap of knowledge has greatly impeded our ability in making informed policy decisions to support sustainable resource management. The root cause of this problem is the lack of tools that can collect information about these animals at large temporal and spatial scales comparable to other physical, chemical, and lower-trophic biological (e.g., chlorophyll) oceanographic variables.&lt;/p>
&lt;p>Gliders have provided unparalleled mobile, persistent access to deep, remote ocean environments at a fraction of the cost of a research vessel. Taking advantage of this unique capability, in this project we aim to develop sampling strategies and data analysis methodologies to enable distributed long-term observation of mid-trophic marine organisms using
&lt;a href="https://apl.uw.edu/project/project.php?id=seaglider_auv" target="_blank" rel="noopener">Seagliders&lt;/a> equipped with acoustic Doppler current profilers (ADCPs).&lt;/p>
&lt;p>&lt;strong>Funding agency&lt;/strong>: NOAA Office of Ocean Exploration and Research
&lt;a href="https://oceanexplorer.noaa.gov/news/oer-updates/2020/fy20-ffo-schedule.html" target="_blank" rel="noopener">FY2020 grants&lt;/a>&lt;/p></description></item><item><title>Computing startup resources</title><link>https://uw-echospace.github.io/group/compute_docs/</link><pubDate>Thu, 07 Dec 2023 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/group/compute_docs/</guid><description>&lt;p>In this collection we share useful starting computing resources among echospace group members.&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://echospace-group-docs.readthedocs.io/en/latest/compute-conda-jupyter.html" target="_blank" rel="noopener">Conda and Jupyter&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://echospace-group-docs.readthedocs.io/en/latest/compute-git.html" target="_blank" rel="noopener">Git and GitHub&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://echospace-group-docs.readthedocs.io/en/latest/compute-cloud.html" target="_blank" rel="noopener">Cloud computing&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://echospace-group-docs.readthedocs.io/en/latest/compute-hpc.html" target="_blank" rel="noopener">HPC and SLURM&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://echospace-group-docs.readthedocs.io/en/latest/compute-osn.html" target="_blank" rel="noopener">OSN data access&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://echospace-group-docs.readthedocs.io/en/latest/compute-others.html" target="_blank" rel="noopener">Other topics to be covered&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Echopype</title><link>https://uw-echospace.github.io/project_others/echopype/</link><pubDate>Sun, 01 Nov 2020 14:50:00 -0800</pubDate><guid>https://uw-echospace.github.io/project_others/echopype/</guid><description>&lt;p>&lt;strong>&lt;code>Echopype&lt;/code>&lt;/strong> is an open-source Python package aimed at
&lt;a href="https://echopype.readthedocs.io/en/latest/why.html" target="_blank" rel="noopener">enhancing the interoperability and scalability&lt;/a>
in processing ocean sonar data for biological information.&lt;/p>
&lt;p>I started building this package in early 2018 when I couldn&amp;rsquo;t find an affordable tool that
allow easy access and manipulation of echosounder data collected by
different sonar models.&lt;/p>
&lt;p>For the latest updates, check out our repo at: &lt;a href="https://github.com/OSOceanAcoustics/echopype">https://github.com/OSOceanAcoustics/echopype&lt;/a>.&lt;/p>
&lt;p>Check out my talk at SciPy 2019 that discussed the goals and philosophy of echopype:
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/qboH7MyHrpU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/p></description></item><item><title>Pattern discovery from long-term echosounder time series</title><link>https://uw-echospace.github.io/project/2019-ooi-mtx-decomp/</link><pubDate>Tue, 01 Jan 2019 14:50:00 -0800</pubDate><guid>https://uw-echospace.github.io/project/2019-ooi-mtx-decomp/</guid><description>&lt;p>&lt;strong>Funding agency&lt;/strong>: National Science Foundation
&lt;a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1849930&amp;amp;HistoricalAwards=false" target="_blank" rel="noopener">Award #1849930&lt;/a>&lt;/p></description></item><item><title>Echo Statistics</title><link>https://uw-echospace.github.io/project/echo-stat-tutorial/</link><pubDate>Sat, 01 Dec 2018 00:00:00 -0800</pubDate><guid>https://uw-echospace.github.io/project/echo-stat-tutorial/</guid><description>&lt;p>For a 2018 tutorial I published with
&lt;a href="https://www2.whoi.edu/staff/tstanton/" target="_blank" rel="noopener">Tim Stanton&lt;/a> and
&lt;a href="https://www.linkedin.com/in/kyungmin-baik-098156149/" target="_blank" rel="noopener">Kyungmin Baik&lt;/a> in
the Journal of the Acoustical Society of America (JASA):&lt;/p>
&lt;p>&lt;strong>Echo statistics associated with discrete scatterers: A tutorial on physics-based methods&lt;/strong>. JASA 144(6): 3124–3171; &lt;a href="https://doi.org/10.1121/1.5052255">https://doi.org/10.1121/1.5052255&lt;/a>&lt;/p>
&lt;p>we provided the Matlab code to reproduce all figures in two forms:&lt;/p>
&lt;ul>
&lt;li>a &lt;em>frozen&lt;/em> version archived with the paper, and&lt;/li>
&lt;li>a GitHub
&lt;a href="https://github.com/leewujung/echo-stats-tutorial" target="_blank" rel="noopener">repository&lt;/a> minted with a
&lt;a href="https://doi.org/10.5281/zenodo.2458776" target="_blank" rel="noopener">DOI from Zenodo&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>This way we can keep the code &amp;ldquo;alive&amp;rdquo; on GitHub but also has a convenient snapshot of the code at the time of the tutorial publication.&lt;/p></description></item><item><title>Modeling sound propagation in the head of toothed whales</title><link>https://uw-echospace.github.io/project/echolocation-comsol/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/project/echolocation-comsol/</guid><description>&lt;p>Toothed whales, including species such as porpoises, dolphins, orca, and sperm whale, possess highly specialized anatomical structures in the head to support their biosonar systems - echolocation - through millions of years of evoluation. These animals have the remarkable ability to detect and track small targets over long distance and discriminate between minute differences between targets using echolocation, with performance often surpassing that of current human-made sonar systems. However, many questions remain in how exactly the unusual anatomical structures in the head of toothed whales are orchestrated to support such performance.&lt;/p>
&lt;p>As part of a Multidisciplinary University Research Initiative (MURI) project, we use finite element modeling techniques in combination with volumetric representations derived from computed tomography (CT) scans to predict the head-related transfer functions (HRTFs) of a dolphin head. The HRTFs summarizes the influence of the head to sounds propagating to the ears. We use HRTFs as a biologically meaningful proxy to provide a physics-based mechanistic understanding of the sound transduction processes.&lt;/p>
&lt;!-- TODO: link ASA 2023 talk -->
&lt;p>&lt;strong>Funding&lt;/strong>: Office of Naval Research, Multidisciplinary University Research Initiative (MURI) program&lt;/p></description></item><item><title>Target search and discrimination by echolocating toothed whales</title><link>https://uw-echospace.github.io/project/echolocation-search/</link><pubDate>Thu, 01 Jan 1970 00:33:38 +0000</pubDate><guid>https://uw-echospace.github.io/project/echolocation-search/</guid><description>&lt;p>Echolocating animals effortlessly navigate, hunt, and interact with their environment, despite cluttered and noisy return signals. Blind expert human echolocators prove that this capacity does not depend exclusively on biological specializations unique to particular species. This project is an integrated component of a larger collaborative Multidisciplinary University Research Initiative (MURI) project focused on active sensing in echolocating marine mammals and humans. The MURI team use both toothed whales (odontocetes) and humans as model systems to identify the neural mechanisms that extract echo-acoustic information and the brain networks that build and learn robust, invariant representations of auditory objects in complex auditory scenes.&lt;/p>
&lt;p>In Echospace, we undertake two interconnected components of this project:&lt;/p>
&lt;ul>
&lt;li>Model the echolocation-based target search by toothed whales as an information-seeking behavior by extending the &lt;em>infotaxis&lt;/em> algorithm originally formulated in moth odor tracking problems into an &lt;em>active sensing&lt;/em> context&lt;/li>
&lt;/ul>
&lt;!-- TODO: link ASA 2019 talk -->
&lt;ul>
&lt;li>Conduct and analyze the coupled acoustic sampling and movement behaviors of an echolocating harbor porpoise in a target discrimination experiment&lt;/li>
&lt;/ul>
&lt;!-- TODO: link ASA 2021, 2023 talks -->
&lt;p>&lt;strong>Funding agency&lt;/strong>: Office of Naval Research, Multidisciplinary University Research Initiative (MURI) program&lt;/p></description></item><item><title>Communication within group</title><link>https://uw-echospace.github.io/group/communication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/group/communication/</guid><description>&lt;h2 id="mode-of-communication">Mode of Communication&lt;/h2>
&lt;p>We use various modes of communication in Echospace to keep ourselves up-to-date on what we are each working on and coordinate.&lt;/p>
&lt;p>Depending on who&amp;rsquo;s involved and the context, we use different methods to communicate. In general:&lt;/p>
&lt;ul>
&lt;li>Internal (among group members): mostly Slack&lt;/li>
&lt;li>External (with colleagues outside of the group): emails&lt;/li>
&lt;li>GitHub: PR and issues, see
&lt;a href="./compute-git.md">here&lt;/a> for how to get started&lt;/li>
&lt;li>Talking: we do talk in analog form!&lt;/li>
&lt;/ul>
&lt;h2 id="expectations">Expectations&lt;/h2>
&lt;ul>
&lt;li>We encourage proactive and frequent communication; for most projects we meet at least weekly to keep each other updated and set short and long term goals&lt;/li>
&lt;li>Immediate response are not expected unless urgent&lt;/li>
&lt;li>People may send messages/emails at their convenient time; aim to respond within a reasonable time frame&lt;/li>
&lt;li>Phone/text: usually reserved for urgent communication or offsite coordination&lt;/li>
&lt;li>Ask us/everyone for help, and provide help if you can!&lt;/li>
&lt;/ul>
&lt;h2 id="slack-workspace">Slack workspace&lt;/h2>
&lt;ul>
&lt;li>Default channels you&amp;rsquo;re added to:
&lt;ul>
&lt;li>#general&lt;/li>
&lt;li>#help&lt;/li>
&lt;li>#random&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Feel free to:
&lt;ul>
&lt;li>Add or remove yourself from channels, but make sure you stay in the know for your projects, as well as group announcements&lt;/li>
&lt;li>Create new channels and announce in the #general channel for others to join&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Interoperable and scalable echosounder data processing with Echopype</title><link>https://uw-echospace.github.io/publication/2024-lee-etal-echopype/</link><pubDate>Wed, 09 Oct 2024 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2024-lee-etal-echopype/</guid><description/></item><item><title>Echostack: An open-source Python software toolbox that democratizes water column sonar dataand processing</title><link>https://uw-echospace.github.io/talk/202407-scipy-echostack/</link><pubDate>Thu, 11 Jul 2024 14:20:00 -0700</pubDate><guid>https://uw-echospace.github.io/talk/202407-scipy-echostack/</guid><description/></item><item><title>Investigation of duty cycles for measuring activity in passive acoustic bat monitoring</title><link>https://uw-echospace.github.io/talk/202405-aditya-asa/</link><pubDate>Tue, 14 May 2024 10:10:00 -0100</pubDate><guid>https://uw-echospace.github.io/talk/202405-aditya-asa/</guid><description/></item><item><title>Variability and influence of fisheries acoustic echogram annotations on machine learning applications</title><link>https://uw-echospace.github.io/talk/202405-asa-ottawa-hake/</link><pubDate>Mon, 13 May 2024 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/talk/202405-asa-ottawa-hake/</guid><description/></item><item><title>Two Pieces of the Same Puzzle: Active and Passive Acoustics for Cross-Trophic Marine Ecosystem Monitoring Part II</title><link>https://uw-echospace.github.io/talk/202405-asa-ottawa-school/</link><pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/talk/202405-asa-ottawa-school/</guid><description/></item><item><title>A ship-to-cloud machine learning pipeline built on the open-source Python Echostack software tools</title><link>https://uw-echospace.github.io/talk/202404-wgfast-ship2cloud/</link><pubDate>Thu, 11 Apr 2024 09:00:00 -0500</pubDate><guid>https://uw-echospace.github.io/talk/202404-wgfast-ship2cloud/</guid><description/></item><item><title>Scalable and configurable echosounder data workflows</title><link>https://uw-echospace.github.io/talk/202404-wgfast-echodataflow/</link><pubDate>Thu, 11 Apr 2024 09:00:00 -0500</pubDate><guid>https://uw-echospace.github.io/talk/202404-wgfast-echodataflow/</guid><description/></item><item><title>A Summer of Refactoring Echoshader!</title><link>https://uw-echospace.github.io/2023/09/18/a-summer-of-refactoring-echoshader/</link><pubDate>Mon, 18 Sep 2023 00:00:00 -0800</pubDate><guid>https://uw-echospace.github.io/2023/09/18/a-summer-of-refactoring-echoshader/</guid><description>&lt;p>&lt;em>Echospace recruited contributor
&lt;a href="https://github.com/ldr426" target="_blank" rel="noopener">Dingrui Lei&lt;/a> in 2023 to refactor an echosounder data interactive visualization package called
&lt;a href="https://github.com/OSOceanAcoustics/echoshader" target="_blank" rel="noopener">echoshader&lt;/a>.&lt;/em>&lt;/p>
&lt;hr>
&lt;h1 id="my-2023-summer-internship-with-echoshader-a-dive-into-advanced-ocean-sonar-data-visualization">My 2023 Summer Internship with Echoshader: A Dive into Advanced Ocean Sonar Data Visualization&lt;/h1>
&lt;p>Author:
&lt;a href="mailto:leidingrui426@gmail.com">Dingrui Lei&lt;/a>&lt;/p>
&lt;p>Ref 1:
&lt;a href="https://docs.google.com/presentation/d/1HmL2-luVmA9T5HfS3L1kBu8c7dDHo75znwaS-8YlTSE/edit#slide=id.p" target="_blank" rel="noopener">Slides&lt;/a> of presentation&lt;/p>
&lt;p>Ref 2:
&lt;a href="https://echoshader--140.org.readthedocs.build/en/140/intro.html" target="_blank" rel="noopener">Docs&lt;/a> for this version&lt;/p>
&lt;p>Hello, readers! I&amp;rsquo;m excited to share my summer internship experience working on the fascinating project, Echoshader. This Python package, designed to enhance the visualization of ocean sonar data, has been my focus this summer. While I won&amp;rsquo;t be delving into technical jargon, I&amp;rsquo;ll give you a glimpse of my journey, the challenges I faced, and the accomplishments achieved during my internship. The prototype was built during
&lt;a href="https://summerofcode.withgoogle.com/programs/2022/organizations/ioos" target="_blank" rel="noopener">GSoC 2022&lt;/a>.&lt;/p>
&lt;h2 id="echoshader-bridging-the-gap-in-ocean-sonar-data-visualization">Echoshader: Bridging the Gap in Ocean Sonar Data Visualization&lt;/h2>
&lt;p>Before I jump into the technical details, let&amp;rsquo;s take a moment to understand the significance of ocean sonar systems. These systems, including echosounders, are the unsung heroes of marine research. They help scientists study marine life by emitting sound waves and analyzing the echoes they bounce back. Think of it as an underwater ultrasound for the ocean. The data generated from these systems is invaluable for monitoring and conserving our marine ecosystems.&lt;/p>
&lt;p>Echoshader, our summer project, aims to make this data more accessible and interactive. It&amp;rsquo;s like a powerful toolset that enables scientists and researchers to visualize and analyze ocean sonar data effortlessly. But let&amp;rsquo;s get into the nitty-gritty of my experience.&lt;/p>
&lt;h2 id="building-the-echoshader-a-structured-journey">Building the Echoshader: A Structured Journey&lt;/h2>
&lt;p>My summer project was all about creating and refining the Echoshader package. This package is the backbone of our mission, providing oceanographers and researchers with the tools they need to visualize and understand ocean sonar data. Here&amp;rsquo;s how I structured my work:&lt;/p>
&lt;h3 id="1-the-echoshader-class-a-controller-for-visualization">1. The Echoshader Class: A Controller for Visualization&lt;/h3>
&lt;p>At the heart of Echoshader lies the Echoshader class. This class is like the conductor of an orchestra, coordinating user interactions, data updates, and visualizations. My task was to make sure this class was robust and user-friendly.&lt;/p>
&lt;p>I defined the class and set up initial values and interactive widgets. These widgets allow users to tweak parameters and explore data interactively.&lt;/p>
&lt;h3 id="2-callbacks-and-streams-making-it-interactive">2. Callbacks and Streams: Making It Interactive&lt;/h3>
&lt;p>Echoshader needed to be interactive, allowing users to explore data dynamically. This required creating callback methods and stream objects. These elements connected user interactions to visualization updates, making the whole experience smooth and intuitive.
&lt;img width="594" alt="image" src="https://github.com/ldr426/add-ldr426-page/assets/56751303/472ca1bf-4ec3-4e27-82db-20dba3f7fa58">&lt;/p>
&lt;h3 id="3-extending-xarray-with-accessors-a-new-level-of-functionality">3. Extending &lt;code>Xarray&lt;/code> with Accessors: A New Level of Functionality&lt;/h3>
&lt;p>One of the exciting challenges I encountered was extending &lt;code>xarray&lt;/code>&amp;rsquo;s functionality using accessors. This means adding custom methods and functionality to &lt;code>xarray&lt;/code> objects, without cluttering the code with custom functions. We created a custom &amp;ldquo;eshader&amp;rdquo; accessor, which allowed us to take echogram visualization to the next level.&lt;/p>
&lt;h2 id="a-glimpse-into-echogram-visualization">A Glimpse into Echogram Visualization&lt;/h2>
&lt;p>Echogram visualization is where the magic happens. It&amp;rsquo;s not just about pretty pictures; it&amp;rsquo;s about gaining insights into marine life and ecosystems.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Echograms for Identifying Fish&lt;/strong>: Fisheries scientists rely on echograms to identify fish aggregations, scrolling through data collected on ships to assess populations.&lt;/li>
&lt;li>&lt;strong>Echograms for Observing Zooplankton&lt;/strong>: Oceanographers use echograms to observe zooplankton movements in mooring data over extended periods.&lt;/li>
&lt;li>&lt;strong>Tricolor Echograms&lt;/strong>: The &amp;ldquo;tricolor&amp;rdquo; echogram helps distinguish different fish species, thanks to its clever mapping of three frequencies to RGB colors.&lt;/li>
&lt;/ul>
&lt;img width="613" alt="single_frequency_echogram" src="https://github.com/ldr426/add-ldr426-page/assets/11621647/a51a6a76-c73d-46c1-84dd-8df643438f07">
&lt;img width="613" alt="tricolor_echogram" src="https://github.com/ldr426/add-ldr426-page/assets/11621647/0ba62c35-5dd0-41db-9225-db0290be1215">
&lt;h2 id="tracking-and-curtain-visualization">Tracking and Curtain Visualization&lt;/h2>
&lt;p>One of the most exciting aspects of Echoshader is tracking and curtain visualization. It&amp;rsquo;s like having a GPS for underwater data.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Echogram-Control Mode&lt;/strong>: Visualizing data on a map helps assess fish associations with environmental variables.&lt;/li>
&lt;li>&lt;strong>Track-Control Mode&lt;/strong>: Highlighting ship track sections on the map while viewing corresponding echograms offers precise insights into marine life at specific locations.&lt;/li>
&lt;li>&lt;strong>Curtain Visualization&lt;/strong>: Representing longer data sections as curtains provides a broader spatial perspective on fish aggregations.
&lt;img width="609" alt="image" src="https://github.com/ldr426/add-ldr426-page/assets/56751303/dab25ce8-bba3-4062-85e9-4ce3231172fc">&lt;/li>
&lt;/ul>
&lt;img width="502" alt="image" src="https://github.com/ldr426/add-ldr426-page/assets/56751303/2a1a33df-c639-4b53-9df2-ae2523cd3901">
&lt;h2 id="histograms-and-statistics-tables-tools-for-deeper-analysis">Histograms and Statistics Tables: Tools for Deeper Analysis&lt;/h2>
&lt;p>Histograms and statistics tables are essential for fisheries scientists.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Focused Analysis&lt;/strong>: Scientists can zoom in on specific data sections to examine volume backscattering strength (Sv) distribution and understand the types of fish present.&lt;/li>
&lt;li>&lt;strong>Multi-Channel Comparisons&lt;/strong>: Comparing Sv distributions across multiple echosounder channels helps determine fish aggregation composition, offering valuable insights into the ecosystem.
&lt;img width="722" alt="image" src="https://github.com/ldr426/add-ldr426-page/assets/56751303/623ca032-cab8-4fe0-8f37-57774a64e1b0">&lt;/li>
&lt;/ul>
&lt;h2 id="in-conclusion-an-incredible-summer-journey">In Conclusion: An Incredible Summer Journey&lt;/h2>
&lt;p>My summer internship with Echoshader has been a remarkable journey. I&amp;rsquo;ve had the privilege of contributing to a project to advance oceanographic research and fisheries science. Echoshader isn&amp;rsquo;t just a package; it&amp;rsquo;s a gateway to uncovering the secrets of our oceans.&lt;/p>
&lt;p>If you&amp;rsquo;re curious about ocean sonar data or want to explore the world of marine life, Echoshader is your partner in discovery. Feel free to reach out if you have questions or want to join us on this exciting journey. Until next time, happy exploring!&lt;/p></description></item><item><title>Investigation of duty cycles in passive acoustic bat monitoring</title><link>https://uw-echospace.github.io/talk/202305-urp-symposium/</link><pubDate>Fri, 19 May 2023 15:30:00 +0200</pubDate><guid>https://uw-echospace.github.io/talk/202305-urp-symposium/</guid><description/></item><item><title>Hello from Dingrui Lei, GSoC contributor of Echoshader!</title><link>https://uw-echospace.github.io/2022/07/28/hello-from-dingrui-lei-gsoc-contributor-of-echoshader/</link><pubDate>Thu, 28 Jul 2022 00:00:00 -0800</pubDate><guid>https://uw-echospace.github.io/2022/07/28/hello-from-dingrui-lei-gsoc-contributor-of-echoshader/</guid><description>&lt;p>&lt;em>Echospace collaborates with the
&lt;a href="https://ioos.us/" target="_blank" rel="noopener">Integrated Ocean Observing Systems (IOOS)&lt;/a> in the
&lt;a href="https://summerofcode.withgoogle.com/" target="_blank" rel="noopener">Google Summer of Code (GSoC)&lt;/a> program in 2022 to jump start an echosounder data interactive visualization package called
&lt;a href="https://github.com/OSOceanAcoustics/echoshader" target="_blank" rel="noopener">echoshader&lt;/a>.&lt;/em>&lt;/p>
&lt;p>&lt;em>
&lt;a href="https://github.com/ldr426" target="_blank" rel="noopener">Dingrui Lei&lt;/a> is our great GSoC contributor, and our very own
&lt;a href="author/don-setiawan">Don Setiawan&lt;/a> is the primary mentor.&lt;/em>&lt;/p>
&lt;hr>
&lt;p>My name is Dingrui Lei and I am a new graduate student at Rice University. My experience has given me a broader understanding of how computer science knowledge can solve engineering problems and facilitate new tech development. I’d like to utilize my computer science knowledge to solve engineering problems.&lt;/p>
&lt;p>Before contacting the
&lt;a href="https://ioos.us/" target="_blank" rel="noopener">IOOS&lt;/a> community, I read the article &amp;ldquo;
&lt;a href="https://storymaps.arcgis.com/stories/e245977def474bdba60952f30576908f" target="_blank" rel="noopener">Understanding Our Ocean with Water-Column Sonar Data&lt;/a>,&amp;rdquo; and an introduction to the project
&lt;a href="https://uw-echospace.github.io/software/echopype/" target="_blank" rel="noopener">echopype&lt;/a>. Sonar is very intriguing to me, it can continuously detect the activities of sea creatures in the dimension of space and time. The depth of fish clusters changing with solar radiation really made me see the splendid usefulness of sonar data.&lt;/p>
&lt;p>&lt;img src="https://ioos.us/images/IOOS_Emblem_Tertiary_B_RGB.png" alt="The IOOS Logo - The U.S. Integrated Ocean Observing System (IOOS)">&lt;/p>
&lt;p>One of the main focuses of the
&lt;a href="https://uw-echospace.github.io/author/echospace/" target="_blank" rel="noopener">Echospace&lt;/a> team is sampling and interpretation of ocean acoustic data.
&lt;a href="https://github.com/OSOceanAcoustics/echopype" target="_blank" rel="noopener">Echopype&lt;/a> sits in the middle, extracts raw data from the cloud or file server, converts them to netCDF or Zarr, and performs denoising and calibration. Another job is to interpret, where I give my effort to build a library called echoshader that can help oceanographers discover certain patterns from it.
&lt;a href="https://github.com/OSOceanAcoustics/echoshader" target="_blank" rel="noopener">Echoshader&lt;/a>, an open source project, aims to enhance the ability to interactively visualize large amounts of cloud-based data to accelerate the data exploration and discovery process. Ocean sonar data are generated from echopype, which handles the normalization, preprocessing and organization of echo data. Echoshader will be developed in parallel with the ongoing development of echopype.&lt;/p>
&lt;p>As a participant of GSoC, I am developing the main APIs of echoshader based on the
&lt;a href="https://holoviz.org/" target="_blank" rel="noopener">HoloViz&lt;/a> suite of tools, test configuration for using echoshader widgets in Panel dashboards, and create Jupyter notebooks to demo use of the combination of tools.&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/max/1400/1*xQEm58a7c_g1Go9G5NMyuw.jpeg" alt="Deploying Panel (Holoviz) dashboards using Heroku Container Registry | by Ali Shahid | Towards Data Science">&lt;/p>
&lt;p>Before starting coding, I read lots of documents to find the most suitable tool. Although there are many excellent and fantastic visualizing libraries with Python, such as plotly and bokh, they can not process xarray directly, which is a kind of multidimensional labeled data massively used in echopype. Then I locked my eyes on HoloViz ecosystem, whose tools and examples generally work with any Python standard data types (lists, dictionaries, etc.), plus Pandas or Dask DataFrames and NumPy, Xarray, or Dask arrays.
After determining which type of tool to use, I began to read a user guide about HoloViz libraries. There are several libraries mainly used in echoshader: hvplot, Holoviews, GeoViews and Panel. Hvplot and HoloViews declare objects for instantly visualizable data, building Bokeh plots from convenient high-level specifications. GeoViews visualize geographic data corresponding to ship survey datasets. Panel assembles grams and control widgets from these different libraries into a layout which could be displayed in a Jupyter notebook and in a standalone servable dashboard. In addition to HoloViz libraries, PyVista and other libraries are involved for 3D extension, which also fit well in panel layout. Also, benchmarking and doc work are required for each module.
Below are some screenshots of the different visualization functionalities I am developing:&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/15334215/186999651-76081a29-11f8-4d37-b3a9-fca0ad49a03c.png" alt="2d_echogram">&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/15334215/186999662-ba744a49-b02e-4451-a716-f8c8df654053.png" alt="tracks">&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/15334215/186999678-2bf77985-aab3-42f8-88f9-1f2c78d3b2eb.png" alt="curtain">&lt;/p>
&lt;p>Although the project is not difficult, there are some other challenges I face. Learning Git and Github is a prerequisite for me to participate in open source projects for the first time. It is also my first time to collaborate with an English-speaking team. I had difficulty reading and writing English documents, not to mention, communicating. Fortunately, the mentors, Wu-jung, Don, Valentina, Brandon and Emilio are all kind and warmhearted, willing to give me suggestions and guidance.&lt;/p>
&lt;p>I really recommend future GSoC participants select the IOOS organization and echospace team as your target and exploit your ability and talent to contribute to the community. Water is extremely significant for holding an adequate food supply and a productive environment for all living organisms. So working here can not just improve your coding and teamwork capability, but also create a beautiful tomorrow for ourselves and our Mother Earth.&lt;/p></description></item><item><title>Understanding echoes</title><link>https://uw-echospace.github.io/talk/202205-asa-denver-keynote/</link><pubDate>Mon, 23 May 2022 16:10:00 +0200</pubDate><guid>https://uw-echospace.github.io/talk/202205-asa-denver-keynote/</guid><description/></item><item><title>Discerning behavioral habits of echolocating bats using acoustical and computational methods</title><link>https://uw-echospace.github.io/talk/202205-urp-symposium/</link><pubDate>Fri, 20 May 2022 15:45:00 +0200</pubDate><guid>https://uw-echospace.github.io/talk/202205-urp-symposium/</guid><description/></item><item><title>Updates from Echopype developers: changes and roadmap</title><link>https://uw-echospace.github.io/talk/202204-wgfast-echopype/</link><pubDate>Wed, 27 Apr 2022 18:10:00 +0200</pubDate><guid>https://uw-echospace.github.io/talk/202204-wgfast-echopype/</guid><description/></item><item><title>Summarizing low-dimensional patterns in long-term echosounder time series from the U.S. Ocean Observatories Initiative network</title><link>https://uw-echospace.github.io/talk/202204-wgfast-ooi-nmf/</link><pubDate>Mon, 25 Apr 2022 18:10:00 +0200</pubDate><guid>https://uw-echospace.github.io/talk/202204-wgfast-ooi-nmf/</guid><description/></item><item><title>Beluga whale (Delphinapterus leucas) acoustic foraging behavior and applications for long term monitoring</title><link>https://uw-echospace.github.io/publication/2021-castellote-etal-plosone-beluga-foraging-monitoring/</link><pubDate>Tue, 30 Nov 2021 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2021-castellote-etal-plosone-beluga-foraging-monitoring/</guid><description/></item><item><title>Scalable, interoperable processing of water column sonar data for biological applications using the echopype Python package</title><link>https://uw-echospace.github.io/talk/202110-ioos-dmac/</link><pubDate>Thu, 28 Oct 2021 15:00:00 -0500</pubDate><guid>https://uw-echospace.github.io/talk/202110-ioos-dmac/</guid><description/></item><item><title>Building a toolbox for studying marine ecology using large ocean sonar datasets</title><link>https://uw-echospace.github.io/talk/202110-uw-data-sci/</link><pubDate>Tue, 05 Oct 2021 16:30:00 -0700</pubDate><guid>https://uw-echospace.github.io/talk/202110-uw-data-sci/</guid><description/></item><item><title>Compact representation of temporal processes in echosounder time series via matrix decomposition</title><link>https://uw-echospace.github.io/publication/2020-lee-staneva-jasa-tsnmf/</link><pubDate>Mon, 30 Nov 2020 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2020-lee-staneva-jasa-tsnmf/</guid><description/></item><item><title>Echo statistics associated with discrete scatterers: A tutorial on physics-based methods</title><link>https://uw-echospace.github.io/publication/2018-stanton-etal-jasa-echo-stat-tutorial/</link><pubDate>Thu, 06 Dec 2018 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2018-stanton-etal-jasa-echo-stat-tutorial/</guid><description/></item><item><title>Macroscopic observations of diel fish movements around a shallow water artificial reef using a mid-frequency horizontal-looking sonar</title><link>https://uw-echospace.github.io/publication/2018-lee-etal-jasa-trex-fish/</link><pubDate>Tue, 18 Sep 2018 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2018-lee-etal-jasa-trex-fish/</guid><description/></item><item><title>Tongue-driven sonar beam steering by a lingual-echolocating fruit bat</title><link>https://uw-echospace.github.io/publication/2017-lee-etal-plosbio-rousettus-bp/</link><pubDate>Fri, 15 Dec 2017 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2017-lee-etal-plosbio-rousettus-bp/</guid><description/></item><item><title>News</title><link>https://uw-echospace.github.io/news/</link><pubDate>Fri, 01 Dec 2017 00:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/news/</guid><description>
&lt;p>&lt;strong>[03/2025]&lt;/strong> Multiple Echospace members will be hosting the first &lt;a href="https://boat-ocean-acoustics.github.io/">Bridge to Ocean Acoustics &amp;amp; Technology (BOAT)&lt;/a> workshop in Seattle!&lt;/p>
&lt;p>&lt;strong>[02/2025]&lt;/strong> Wu-Jung was awarded for the 2025 APL Science and Engineering Achievement Award! Congratulations!&lt;/p>
&lt;p>&lt;strong>[02/2025]&lt;/strong> Caesar was accepted to the UW ECE PhD program and will start this fall, continuing his research in Echospace! Congratulations, Caesar!&lt;/p>
&lt;p>&lt;strong>[10/2025]&lt;/strong> &lt;a href="https://uw-echospace.github.io/author/ameena-majeed">Ameena Majeed&lt;/a> joied Echospace as an Undergrad Research Assistant. Welcome!&lt;/p>
&lt;p>&lt;strong>[08/2025]&lt;/strong> &lt;a href="https://uw-echospace.github.io/author/aidan-lee">Aidan Lee&lt;/a> joied Echospace as an Undergrad Research Assistant. Welcome!&lt;/p>
&lt;p>&lt;strong>[07/2024]&lt;/strong> Wu-Jung gave a talk on our &lt;a href="https://proceedings.scipy.org/articles/WXRH8633">Echostack software suite&lt;/a> and Valentina presented a poster on the &lt;a href="https://proceedings.scipy.org/articles/JXDK4427">Echodataflow package&lt;/a> at the Scipy 2024 conference.&lt;/p>
&lt;p>&lt;strong>[06/2024]&lt;/strong> Aditya attended the &lt;a href="https://eos.unh.edu/center-acoustics-research-education/education/bioacoustic-summer-school-seabass">BioAcoustic Summer School (SeaBASS) in the University of New Hampshire&lt;/a> and met some inspiring lecturers and students! Wu-Jung also gave a lecture on Fundamentals of Ocean Acoustics!&lt;/p>
&lt;p>&lt;strong>[05/2024]&lt;/strong> Wu-Jung and Aditya presented two talks in the &lt;a href="https://acousticalsociety.org/ottawa/">Ottawa ASA Meeting&lt;/a> on &lt;a href="talk/202405-asa-ottawa-hake/">evaluating the hake ML model&lt;/a> and &lt;a href="talk/202405-aditya-asa/">the impacts of duty-cycle PAM for bats&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[05/2024]&lt;/strong> Wu-Jung gave a lecture on active acoustic ocean sensing and a best practice in scientific computing tutorial at &lt;a href="https://acousticalsociety.org/asa-school-2024/">ASA School 2024 in Ottawa&lt;/a> as an instructor and met some wonderful students!&lt;/p>
&lt;p>&lt;strong>[04/2024]&lt;/strong> Wu-Jung and Valentina presented two talks at the &lt;a href="https://www-iuem.univ-brest.fr/wgfast/?lang=en">WGFAST 2024&lt;/a> meeting in France on pipelines and software tools for echosounder data processing on both ship and cloud.&lt;/p>
&lt;p>&lt;strong>[04/2024]&lt;/strong> Wu-Jung presented on &lt;a href="https://echolevels.readthedocs.io/en/latest/levels_proposed.html">Echosounder Data Processing Levels&lt;/a> (with contributions from Emilio, Brandyn, and Valentina) at the Global Acoustics INteroperable (GAIN) workshop associated with the WGFAST 2024 meeting.&lt;/p>
&lt;p>&lt;strong>[03/2024]&lt;/strong> Wu-Jung and Valentina hosted 2 Capstone teams in the Master of Science in Data Science program for sonar data processing and automatic bat call detection.&lt;/p>
&lt;p>&lt;strong>[12/2023]&lt;/strong> We welcome &lt;a href="https://uw-echospace.github.io/author/brandyn-lucca">Dr. Brandyn Lucca&lt;/a> to join Echospace as a &lt;a href="https://seeyourselfapl.uw.edu/seed-postdoctoral-fellowship/">SEED&lt;/a> postdoctoral fellow!&lt;/p>
&lt;p>&lt;strong>[12/2023]&lt;/strong> Soham gave a talk at 2023 PyData Global &amp;ndash; check out his &lt;a href="https://global2023.pydata.org/cfp/talk/FF9MXK/">abstract&lt;/a> and the &lt;a href="https://www.youtube.com/watch?v=9hr9rSOq5jQ">video recording&lt;/a>!&lt;/p>
&lt;p>&lt;strong>[10/2023]&lt;/strong> Valentina and Wu-Jung gave a talk and a poster presentation in the &lt;a href="https://meetings.pices.int/meetings/annual/2023/PICES/news">2023 North Pacific Marine Science Organization (PICES) meeting&lt;/a> in Seattle.&lt;/p>
&lt;p>&lt;strong>[09/2023]&lt;/strong> YeonJoon was selected as a &lt;a href="https://escience.washington.edu/people/postdoctoral-fellows/">UW Data Science Postdoctoral Fellow&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[09/2023]&lt;/strong> Wu-Jung joined the NOAA NCEI Water Column Sonar Data Archive stakeholder workshop and engaged in Echopype Q&amp;amp;As.&lt;/p>
&lt;p>&lt;strong>[08/2023]&lt;/strong> Wu-Jung, Emilio, and Valentina hosted &lt;a href="https://oceanhackweek.org/about/pasthackweeks.html#ohw23">OceanHackWeek 2023&lt;/a> at UW with an international organizer team!&lt;/p>
&lt;p>&lt;strong>[05/2023]&lt;/strong> &lt;a href="https://uw-echospace.github.io/author/caesar-tuguinay">Caesar Tuguinay&lt;/a> joined the Echospace group as a Research Assistant. Welcome!&lt;/p>
&lt;p>&lt;strong>[05/2023]&lt;/strong> We welcome Dingrui Lei and &lt;a href="https://uw-echospace.github.io/author/soham-kishor-butala">Soham Butala&lt;/a> to join Echospace as summer interns!&lt;/p>
&lt;p>&lt;strong>[06/2023]&lt;/strong> Valentina and Wu-Jung went to sea with the Hake survey on the NOAA FSV Bell M. Shimada!&lt;/p>
&lt;p>&lt;strong>[05/2023]&lt;/strong> YeonJoon and Wu-Jung gave two talks on target discrimination behavior by a harbor porpoise and numerical modeling of sound transduction in dolphin head in the &lt;a href="https://acousticalsociety.org/asa-meetings/">Chicago ASA meeting&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[05/2023]&lt;/strong> Aditya presented his ongoing research on the effects of subsampling for passive acoustic monitoring of bats at &lt;a href="https://expo.uw.edu/expo/apply/676/proceedings">UW&amp;rsquo;s 26th Annual Undergraduate Research Symposium&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[03/2023]&lt;/strong> Valentina and Wu-Jung gave two talks on our software and machine learning developments at the &lt;a href="https://seagrant.umaine.edu/focus-areas/healthy-coastal-ecosystems/ices-fisheries-and-plankton-acoustics-symposium/">2023 ICES Fisheries and Plankton Acoustics Symposium&lt;/a> in Portland, Maine, and together with Emilio engaged with the international fisheries acoustic community in data format discussions.&lt;/p>
&lt;p>&lt;strong>[02/2023]&lt;/strong> Wu-Jung was invited to serve on the committee for &lt;a href="https://www.nationalacademies.org/our-work/ocean-acoustics-education-and-expertise">Ocean Acoustics Education and Expertise&lt;/a> of the National Academies, comissioned by ONR.&lt;/p>
&lt;p>&lt;strong>[12/2022]&lt;/strong> Aditya has been awarded the &lt;a href="https://expd.uw.edu/mge/apply/research/">Mary Gates Research Scholarship&lt;/a> for his research on passive acoustic monitoring of bats in the Union Bay Natural Area!&lt;/p>
&lt;p>&lt;strong>[08/2022]&lt;/strong> Many of us in Echospace and alumnus Derya are hosting the &lt;a href="https://oceanhackweek.github.io/ohw22/index.html">OceanHackWeek 2022&lt;/a> &lt;a href="https://oceanhackweek.github.io/ohw22/seattle/index.html">Northwest satellite&lt;/a> this week!&lt;/p>
&lt;p>&lt;strong>[07/2022]&lt;/strong> We welcome &lt;a href="https://uw-echospace.github.io/author/yeonjoon-cheong">Dr. YeonJoon Cheong&lt;/a> to join Echospace as a postdoc scholar!&lt;/p>
&lt;p>&lt;strong>[05/2022]&lt;/strong> We have released a &lt;a href="https://echopype.readthedocs.io/en/stable/whats-new.html">new, major version of echopype, 0.6.0&lt;/a>. There are significant breaking changes, but also significant improvements in convention adherence, consistency across sensors, and dataset documentation.&lt;/p>
&lt;p>&lt;strong>[05/2022]&lt;/strong> Wu-Jung will be giving the keynote lecture on &amp;ldquo;Understanding Echoes&amp;rdquo; in the &lt;a href="https://acousticalsociety.org/asa-meetings/#KL">ASA Denver meeting&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[05/2022]&lt;/strong> Aditya gave a talk on using machine learning to monitor bats in &lt;a href="https://expo.uw.edu/expo/apply/635/proceedings">UW&amp;rsquo;s 25th Annual Undergraduate Research Symposium&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[04/2022]&lt;/strong> Wu-Jung and Emilio gave two talks on &lt;a href="https://uw-echospace.github.io/talk/202204-wgfast-echopype">echopype updates and roadmap&lt;/a> in the 2022 WGFAST meeting and the 2022 NOAA NCEI Water Column Sonar Data Archive workshop.&lt;/p>
&lt;p>&lt;strong>[04/2022]&lt;/strong> Valentina gave a talk on &lt;a href="https://uw-echospace.github.io/talk/202204-wgfast-ooi-nmf">analyzing OOI echosounder data using matrix decomposition&lt;/a> in the 2022 WGFAST meeting.&lt;/p>
&lt;p>&lt;strong>[11/2021]&lt;/strong> Valentina gave a tutorial at the Seattle ASA meeting on &lt;a href="https://acousticalsociety.org/wp-content/uploads/2022/01/MeetingInformationSeattle.pdf#page=3">Software Best Practices&lt;/a>&lt;/p>
&lt;p>&lt;strong>[11/2021]&lt;/strong> New paper &lt;a href="https://doi.org/10.1371/journal.pone.0260485">&amp;ldquo;Beluga whale (&lt;em>Delphinapterus leucas&lt;/em>) acoustic foraging behavior and applications for long term monitoring&amp;rdquo;&lt;/a> was published in PLOS One!&lt;/p>
&lt;p>&lt;strong>[10/2021]&lt;/strong> New preprint &lt;a href="https://arxiv.org/abs/2111.00187">&amp;ldquo;Echopype: A Python library for interoperable and scalable processing of water column sonar data for biological information&amp;rdquo;&lt;/a> was posted on arXiv!&lt;/p>
&lt;p>&lt;strong>[10/2021]&lt;/strong> Emilio and Wu-Jung gave the IOOS DMAC webinar on &lt;a href="https://uw-echospace.github.io/talk/202110-ioos-dmac">&amp;ldquo;Scalable, interoperable processing of water column sonar data for biological applications using the echopype Python package&amp;rdquo;&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[10/2021]&lt;/strong> Wu-Jung gave the UW Data Science Seminar on &lt;a href="https://uw-echospace.github.io/talk/202110-uw-data-sci">&amp;ldquo;Building a toolbox for studying marine ecology using large ocean sonar datasets&amp;rdquo;&lt;/a>.&lt;/p>
&lt;p>&lt;strong>[09/2021]&lt;/strong> Wu-Jung and Linda successfully completed this summer&amp;rsquo;s fieldwork evaluating the use of an ADCP-equipped glider as a biological monitoring tool. Check out &lt;a href="https://oceanexplorer.noaa.gov/technology/development-partnerships/21adcp-gliders/welcome.html">NOAA Exploration&amp;rsquo;s coverage of this mission&lt;/a>!&lt;/p></description></item><item><title>Dynamic echo information guides flight in the big brown bat</title><link>https://uw-echospace.github.io/publication/2016-warnecke-etal-frontier-echo-flow/</link><pubDate>Tue, 01 Mar 2016 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2016-warnecke-etal-frontier-echo-flow/</guid><description/></item><item><title>Statistics of broadband echoes: application to acoustic estimates of numerical density of fish</title><link>https://uw-echospace.github.io/publication/2015-lee-stanton-joe-broadband/</link><pubDate>Tue, 01 Dec 2015 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2015-lee-stanton-joe-broadband/</guid><description/></item><item><title>Bats regulate biosonar based on the availability of visual information</title><link>https://uw-echospace.github.io/publication/2015-danilovich-etal-currbio-rousettus-light/</link><pubDate>Wed, 01 Jul 2015 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2015-danilovich-etal-currbio-rousettus-light/</guid><description/></item><item><title>Can the elongated hindwing tails of fluttering moths serve as false sonar targets to divert bat attacks?</title><link>https://uw-echospace.github.io/publication/2016-lee-moss-jasa-luna-moth/</link><pubDate>Fri, 01 May 2015 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2016-lee-moss-jasa-luna-moth/</guid><description/></item><item><title>Statistics of echoes from mixed assemblages of scatterers with different scattering amplitudes and numerical densities</title><link>https://uw-echospace.github.io/publication/2014-lee-stanton-joe-mixed/</link><pubDate>Mon, 13 Jan 2014 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2014-lee-stanton-joe-mixed/</guid><description/></item><item><title>Orientation dependence of broadband acoustic backscattering from live squid</title><link>https://uw-echospace.github.io/publication/2012-lee-etal-jasa-squid/</link><pubDate>Fri, 01 Jun 2012 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2012-lee-etal-jasa-squid/</guid><description/></item><item><title>Long-duration anesthetization of squid (Doryteuthis pealeii)</title><link>https://uw-echospace.github.io/publication/2010-mooney-etal-squid-sedation/</link><pubDate>Thu, 01 Apr 2010 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2010-mooney-etal-squid-sedation/</guid><description/></item><item><title>The acoustic field on the forehead of echolocating Atlantic bottlenose dolphins (Tursiops truncatus)</title><link>https://uw-echospace.github.io/publication/2010-au-etal-jasa-tursiops-suctioncup/</link><pubDate>Mon, 01 Mar 2010 09:00:00 +0000</pubDate><guid>https://uw-echospace.github.io/publication/2010-au-etal-jasa-tursiops-suctioncup/</guid><description/></item></channel></rss>