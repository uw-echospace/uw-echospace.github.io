<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts | Echospace @ UW</title><link>https://uw-echospace.github.io/post/</link><atom:link href="https://uw-echospace.github.io/post/index.xml" rel="self" type="application/rss+xml"/><description>Posts</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 18 Sep 2023 00:00:00 -0800</lastBuildDate><image><url>https://uw-echospace.github.io/images/icon_hu9a3e81eca2a83564e549c2cdc32b0637_27049_512x512_fill_lanczos_center_2.png</url><title>Posts</title><link>https://uw-echospace.github.io/post/</link></image><item><title>A Summer of Refactoring Echoshader!</title><link>https://uw-echospace.github.io/2023/09/18/a-summer-of-refactoring-echoshader/</link><pubDate>Mon, 18 Sep 2023 00:00:00 -0800</pubDate><guid>https://uw-echospace.github.io/2023/09/18/a-summer-of-refactoring-echoshader/</guid><description>&lt;p>&lt;em>Echospace recruited contributor
&lt;a href="https://github.com/ldr426" target="_blank" rel="noopener">Dingrui Lei&lt;/a> in 2023 to refactor an echosounder data interactive visualization package called
&lt;a href="https://github.com/OSOceanAcoustics/echoshader" target="_blank" rel="noopener">echoshader&lt;/a>.&lt;/em>&lt;/p>
&lt;hr>
&lt;h1 id="my-2023-summer-internship-with-echoshader-a-dive-into-advanced-ocean-sonar-data-visualization">My 2023 Summer Internship with Echoshader: A Dive into Advanced Ocean Sonar Data Visualization&lt;/h1>
&lt;p>Author:
&lt;a href="mailto:leidingrui426@gmail.com">Dingrui Lei&lt;/a>&lt;/p>
&lt;p>Ref 1:
&lt;a href="https://docs.google.com/presentation/d/1HmL2-luVmA9T5HfS3L1kBu8c7dDHo75znwaS-8YlTSE/edit#slide=id.p" target="_blank" rel="noopener">Slides&lt;/a> of presentation&lt;/p>
&lt;p>Ref 2:
&lt;a href="https://echoshader--140.org.readthedocs.build/en/140/intro.html" target="_blank" rel="noopener">Docs&lt;/a> for this version&lt;/p>
&lt;p>Hello, readers! I&amp;rsquo;m excited to share my summer internship experience working on the fascinating project, Echoshader. This Python package, designed to enhance the visualization of ocean sonar data, has been my focus this summer. While I won&amp;rsquo;t be delving into technical jargon, I&amp;rsquo;ll give you a glimpse of my journey, the challenges I faced, and the accomplishments achieved during my internship. The prototype was built during
&lt;a href="https://summerofcode.withgoogle.com/programs/2022/organizations/ioos" target="_blank" rel="noopener">GSoC 2022&lt;/a>.&lt;/p>
&lt;h2 id="echoshader-bridging-the-gap-in-ocean-sonar-data-visualization">Echoshader: Bridging the Gap in Ocean Sonar Data Visualization&lt;/h2>
&lt;p>Before I jump into the technical details, let&amp;rsquo;s take a moment to understand the significance of ocean sonar systems. These systems, including echosounders, are the unsung heroes of marine research. They help scientists study marine life by emitting sound waves and analyzing the echoes they bounce back. Think of it as an underwater ultrasound for the ocean. The data generated from these systems is invaluable for monitoring and conserving our marine ecosystems.&lt;/p>
&lt;p>Echoshader, our summer project, aims to make this data more accessible and interactive. It&amp;rsquo;s like a powerful toolset that enables scientists and researchers to visualize and analyze ocean sonar data effortlessly. But let&amp;rsquo;s get into the nitty-gritty of my experience.&lt;/p>
&lt;h2 id="building-the-echoshader-a-structured-journey">Building the Echoshader: A Structured Journey&lt;/h2>
&lt;p>My summer project was all about creating and refining the Echoshader package. This package is the backbone of our mission, providing oceanographers and researchers with the tools they need to visualize and understand ocean sonar data. Here&amp;rsquo;s how I structured my work:&lt;/p>
&lt;h3 id="1-the-echoshader-class-a-controller-for-visualization">1. The Echoshader Class: A Controller for Visualization&lt;/h3>
&lt;p>At the heart of Echoshader lies the Echoshader class. This class is like the conductor of an orchestra, coordinating user interactions, data updates, and visualizations. My task was to make sure this class was robust and user-friendly.&lt;/p>
&lt;p>I defined the class and set up initial values and interactive widgets. These widgets allow users to tweak parameters and explore data interactively.&lt;/p>
&lt;h3 id="2-callbacks-and-streams-making-it-interactive">2. Callbacks and Streams: Making It Interactive&lt;/h3>
&lt;p>Echoshader needed to be interactive, allowing users to explore data dynamically. This required creating callback methods and stream objects. These elements connected user interactions to visualization updates, making the whole experience smooth and intuitive.
&lt;img width="594" alt="image" src="https://github.com/ldr426/add-ldr426-page/assets/56751303/472ca1bf-4ec3-4e27-82db-20dba3f7fa58">&lt;/p>
&lt;h3 id="3-extending-xarray-with-accessors-a-new-level-of-functionality">3. Extending &lt;code>Xarray&lt;/code> with Accessors: A New Level of Functionality&lt;/h3>
&lt;p>One of the exciting challenges I encountered was extending &lt;code>xarray&lt;/code>&amp;rsquo;s functionality using accessors. This means adding custom methods and functionality to &lt;code>xarray&lt;/code> objects, without cluttering the code with custom functions. We created a custom &amp;ldquo;eshader&amp;rdquo; accessor, which allowed us to take echogram visualization to the next level.&lt;/p>
&lt;h2 id="a-glimpse-into-echogram-visualization">A Glimpse into Echogram Visualization&lt;/h2>
&lt;p>Echogram visualization is where the magic happens. It&amp;rsquo;s not just about pretty pictures; it&amp;rsquo;s about gaining insights into marine life and ecosystems.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Echograms for Identifying Fish&lt;/strong>: Fisheries scientists rely on echograms to identify fish aggregations, scrolling through data collected on ships to assess populations.&lt;/li>
&lt;li>&lt;strong>Echograms for Observing Zooplankton&lt;/strong>: Oceanographers use echograms to observe zooplankton movements in mooring data over extended periods.&lt;/li>
&lt;li>&lt;strong>Tricolor Echograms&lt;/strong>: The &amp;ldquo;tricolor&amp;rdquo; echogram helps distinguish different fish species, thanks to its clever mapping of three frequencies to RGB colors.&lt;/li>
&lt;/ul>
&lt;img width="613" alt="single_frequency_echogram" src="https://github.com/ldr426/add-ldr426-page/assets/11621647/a51a6a76-c73d-46c1-84dd-8df643438f07">
&lt;img width="613" alt="tricolor_echogram" src="https://github.com/ldr426/add-ldr426-page/assets/11621647/0ba62c35-5dd0-41db-9225-db0290be1215">
&lt;h2 id="tracking-and-curtain-visualization">Tracking and Curtain Visualization&lt;/h2>
&lt;p>One of the most exciting aspects of Echoshader is tracking and curtain visualization. It&amp;rsquo;s like having a GPS for underwater data.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Echogram-Control Mode&lt;/strong>: Visualizing data on a map helps assess fish associations with environmental variables.&lt;/li>
&lt;li>&lt;strong>Track-Control Mode&lt;/strong>: Highlighting ship track sections on the map while viewing corresponding echograms offers precise insights into marine life at specific locations.&lt;/li>
&lt;li>&lt;strong>Curtain Visualization&lt;/strong>: Representing longer data sections as curtains provides a broader spatial perspective on fish aggregations.
&lt;img width="609" alt="image" src="https://github.com/ldr426/add-ldr426-page/assets/56751303/dab25ce8-bba3-4062-85e9-4ce3231172fc">&lt;/li>
&lt;/ul>
&lt;img width="502" alt="image" src="https://github.com/ldr426/add-ldr426-page/assets/56751303/2a1a33df-c639-4b53-9df2-ae2523cd3901">
&lt;h2 id="histograms-and-statistics-tables-tools-for-deeper-analysis">Histograms and Statistics Tables: Tools for Deeper Analysis&lt;/h2>
&lt;p>Histograms and statistics tables are essential for fisheries scientists.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Focused Analysis&lt;/strong>: Scientists can zoom in on specific data sections to examine volume backscattering strength (Sv) distribution and understand the types of fish present.&lt;/li>
&lt;li>&lt;strong>Multi-Channel Comparisons&lt;/strong>: Comparing Sv distributions across multiple echosounder channels helps determine fish aggregation composition, offering valuable insights into the ecosystem.
&lt;img width="722" alt="image" src="https://github.com/ldr426/add-ldr426-page/assets/56751303/623ca032-cab8-4fe0-8f37-57774a64e1b0">&lt;/li>
&lt;/ul>
&lt;h2 id="in-conclusion-an-incredible-summer-journey">In Conclusion: An Incredible Summer Journey&lt;/h2>
&lt;p>My summer internship with Echoshader has been a remarkable journey. I&amp;rsquo;ve had the privilege of contributing to a project to advance oceanographic research and fisheries science. Echoshader isn&amp;rsquo;t just a package; it&amp;rsquo;s a gateway to uncovering the secrets of our oceans.&lt;/p>
&lt;p>If you&amp;rsquo;re curious about ocean sonar data or want to explore the world of marine life, Echoshader is your partner in discovery. Feel free to reach out if you have questions or want to join us on this exciting journey. Until next time, happy exploring!&lt;/p></description></item><item><title>Hello from Dingrui Lei, GSoC contributor of Echoshader!</title><link>https://uw-echospace.github.io/2022/07/28/hello-from-dingrui-lei-gsoc-contributor-of-echoshader/</link><pubDate>Thu, 28 Jul 2022 00:00:00 -0800</pubDate><guid>https://uw-echospace.github.io/2022/07/28/hello-from-dingrui-lei-gsoc-contributor-of-echoshader/</guid><description>&lt;p>&lt;em>Echospace collaborates with the
&lt;a href="https://ioos.us/" target="_blank" rel="noopener">Integrated Ocean Observing Systems (IOOS)&lt;/a> in the
&lt;a href="https://summerofcode.withgoogle.com/" target="_blank" rel="noopener">Google Summer of Code (GSoC)&lt;/a> program in 2022 to jump start an echosounder data interactive visualization package called
&lt;a href="https://github.com/OSOceanAcoustics/echoshader" target="_blank" rel="noopener">echoshader&lt;/a>.&lt;/em>&lt;/p>
&lt;p>&lt;em>
&lt;a href="https://github.com/ldr426" target="_blank" rel="noopener">Dingrui Lei&lt;/a> is our great GSoC contributor, and our very own
&lt;a href="author/don-setiawan">Don Setiawan&lt;/a> is the primary mentor.&lt;/em>&lt;/p>
&lt;hr>
&lt;p>My name is Dingrui Lei and I am a new graduate student at Rice University. My experience has given me a broader understanding of how computer science knowledge can solve engineering problems and facilitate new tech development. I’d like to utilize my computer science knowledge to solve engineering problems.&lt;/p>
&lt;p>Before contacting the
&lt;a href="https://ioos.us/" target="_blank" rel="noopener">IOOS&lt;/a> community, I read the article &amp;ldquo;
&lt;a href="https://storymaps.arcgis.com/stories/e245977def474bdba60952f30576908f" target="_blank" rel="noopener">Understanding Our Ocean with Water-Column Sonar Data&lt;/a>,&amp;rdquo; and an introduction to the project
&lt;a href="https://uw-echospace.github.io/software/echopype/" target="_blank" rel="noopener">echopype&lt;/a>. Sonar is very intriguing to me, it can continuously detect the activities of sea creatures in the dimension of space and time. The depth of fish clusters changing with solar radiation really made me see the splendid usefulness of sonar data.&lt;/p>
&lt;p>&lt;img src="https://ioos.us/images/IOOS_Emblem_Tertiary_B_RGB.png" alt="The IOOS Logo - The U.S. Integrated Ocean Observing System (IOOS)">&lt;/p>
&lt;p>One of the main focuses of the
&lt;a href="https://uw-echospace.github.io/author/echospace/" target="_blank" rel="noopener">Echospace&lt;/a> team is sampling and interpretation of ocean acoustic data.
&lt;a href="https://github.com/OSOceanAcoustics/echopype" target="_blank" rel="noopener">Echopype&lt;/a> sits in the middle, extracts raw data from the cloud or file server, converts them to netCDF or Zarr, and performs denoising and calibration. Another job is to interpret, where I give my effort to build a library called echoshader that can help oceanographers discover certain patterns from it.
&lt;a href="https://github.com/OSOceanAcoustics/echoshader" target="_blank" rel="noopener">Echoshader&lt;/a>, an open source project, aims to enhance the ability to interactively visualize large amounts of cloud-based data to accelerate the data exploration and discovery process. Ocean sonar data are generated from echopype, which handles the normalization, preprocessing and organization of echo data. Echoshader will be developed in parallel with the ongoing development of echopype.&lt;/p>
&lt;p>As a participant of GSoC, I am developing the main APIs of echoshader based on the
&lt;a href="https://holoviz.org/" target="_blank" rel="noopener">HoloViz&lt;/a> suite of tools, test configuration for using echoshader widgets in Panel dashboards, and create Jupyter notebooks to demo use of the combination of tools.&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/max/1400/1*xQEm58a7c_g1Go9G5NMyuw.jpeg" alt="Deploying Panel (Holoviz) dashboards using Heroku Container Registry | by Ali Shahid | Towards Data Science">&lt;/p>
&lt;p>Before starting coding, I read lots of documents to find the most suitable tool. Although there are many excellent and fantastic visualizing libraries with Python, such as plotly and bokh, they can not process xarray directly, which is a kind of multidimensional labeled data massively used in echopype. Then I locked my eyes on HoloViz ecosystem, whose tools and examples generally work with any Python standard data types (lists, dictionaries, etc.), plus Pandas or Dask DataFrames and NumPy, Xarray, or Dask arrays.
After determining which type of tool to use, I began to read a user guide about HoloViz libraries. There are several libraries mainly used in echoshader: hvplot, Holoviews, GeoViews and Panel. Hvplot and HoloViews declare objects for instantly visualizable data, building Bokeh plots from convenient high-level specifications. GeoViews visualize geographic data corresponding to ship survey datasets. Panel assembles grams and control widgets from these different libraries into a layout which could be displayed in a Jupyter notebook and in a standalone servable dashboard. In addition to HoloViz libraries, PyVista and other libraries are involved for 3D extension, which also fit well in panel layout. Also, benchmarking and doc work are required for each module.
Below are some screenshots of the different visualization functionalities I am developing:&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/15334215/186999651-76081a29-11f8-4d37-b3a9-fca0ad49a03c.png" alt="2d_echogram">&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/15334215/186999662-ba744a49-b02e-4451-a716-f8c8df654053.png" alt="tracks">&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/15334215/186999678-2bf77985-aab3-42f8-88f9-1f2c78d3b2eb.png" alt="curtain">&lt;/p>
&lt;p>Although the project is not difficult, there are some other challenges I face. Learning Git and Github is a prerequisite for me to participate in open source projects for the first time. It is also my first time to collaborate with an English-speaking team. I had difficulty reading and writing English documents, not to mention, communicating. Fortunately, the mentors, Wu-jung, Don, Valentina, Brandon and Emilio are all kind and warmhearted, willing to give me suggestions and guidance.&lt;/p>
&lt;p>I really recommend future GSoC participants select the IOOS organization and echospace team as your target and exploit your ability and talent to contribute to the community. Water is extremely significant for holding an adequate food supply and a productive environment for all living organisms. So working here can not just improve your coding and teamwork capability, but also create a beautiful tomorrow for ourselves and our Mother Earth.&lt;/p></description></item></channel></rss>